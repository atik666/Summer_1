{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:33:53.570525Z",
     "start_time": "2020-04-16T02:33:53.256842Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# root_path = './../datasets'\n",
    "# processed_folder =  os.path.join(root_path)\n",
    "\n",
    "# zip_ref = zipfile.ZipFile(os.path.join(root_path,'omniglot.zip'), 'r')\n",
    "# zip_ref.extractall(root_path)\n",
    "# zip_ref.close()\n",
    "root_dir = './../datasets/omniglot/python'\n",
    "root_dir_train = os.path.join(root_dir,'images_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:55:03.418079Z",
     "start_time": "2020-04-07T06:55:03.346124Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "拿到原始数据之后先将下面的代码取消注释，进行数据预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:33:55.423210Z",
     "start_time": "2020-04-16T02:33:55.405143Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 数据预处理\n",
    "# import torchvision.transforms as transforms\n",
    "# from PIL import Image\n",
    "\n",
    "# '''\n",
    "# an example of img_items:\n",
    "# ( '0709_17.png',\n",
    "#   'Alphabet_of_the_Magi/character01',\n",
    "#   './../datasets/omniglot/python/images_background/Alphabet_of_the_Magi/character01')\n",
    "# '''\n",
    "\n",
    "\n",
    "# root_dir_train = os.path.join(root_dir, 'images_background')\n",
    "# root_dir_test = os.path.join(root_dir, 'images_evaluation')\n",
    "\n",
    "# def find_classes(root_dir_train):\n",
    "#     img_items = []\n",
    "#     for (root, dirs, files) in os.walk(root_dir_train): \n",
    "#         for file in files:\n",
    "#             if (file.endswith(\"png\")):\n",
    "#                 r = root.split('/')\n",
    "#                 img_items.append((file, r[-2] + \"/\" + r[-1], root))\n",
    "#     print(\"== Found %d items \" % len(img_items))\n",
    "#     return img_items\n",
    "\n",
    "# ## 构建一个词典{class:idx}\n",
    "# def index_classes(items):\n",
    "#     class_idx = {}\n",
    "#     count = 0\n",
    "#     for item in items:\n",
    "#         if item[1] not in class_idx:\n",
    "#             class_idx[item[1]] = count\n",
    "#             count += 1\n",
    "#     print('== Found {} classes'.format(len(class_idx)))\n",
    "#     return class_idx\n",
    "        \n",
    "\n",
    "# img_items_train =  find_classes(root_dir_train) # [(file1, label1, root1),..]\n",
    "# img_items_test = find_classes(root_dir_test)\n",
    "\n",
    "# class_idx_train = index_classes(img_items_train)\n",
    "# class_idx_test = index_classes(img_items_test)\n",
    "\n",
    "\n",
    "# def generate_temp(img_items,class_idx):\n",
    "#     temp = dict()\n",
    "#     for imgname, classes, dirs in img_items:\n",
    "#         img = '{}/{}'.format(dirs, imgname)\n",
    "#         label = class_idx[classes]\n",
    "#         transform = transforms.Compose([lambda img: Image.open(img).convert('L'),\n",
    "#                                   lambda img: img.resize((28,28)),\n",
    "#                                   lambda img: np.reshape(img, (28,28,1)),\n",
    "#                                   lambda img: np.transpose(img, [2,0,1]),\n",
    "#                                   lambda img: img/255.\n",
    "#                                   ])\n",
    "#         img = transform(img)\n",
    "#         if label in temp.keys():\n",
    "#             temp[label].append(img)\n",
    "#         else:\n",
    "#             temp[label] = [img]\n",
    "#     print('begin to generate omniglot.npy')\n",
    "#     return temp\n",
    "#     ## 每个字符包含20个样本\n",
    "\n",
    "# temp_train = generate_temp(img_items_train, class_idx_train)\n",
    "# temp_test = generate_temp(img_items_test, class_idx_test)\n",
    "\n",
    "# img_list = []\n",
    "# for label, imgs in temp_train.items():\n",
    "#     img_list.append(np.array(imgs))\n",
    "# img_list = np.array(img_list).astype(np.float) # [[20 imgs],..., 1623 classes in total]\n",
    "# print('data shape:{}'.format(img_list.shape)) # (964, 20, 1, 28, 28)\n",
    "# np.save(os.path.join(root_dir, 'omniglot_train.npy'), img_list)\n",
    "# print('end.')\n",
    "\n",
    "\n",
    "# img_list = []\n",
    "# for label, imgs in temp_test.items():\n",
    "#     img_list.append(np.array(imgs))\n",
    "# img_list = np.array(img_list).astype(np.float) # [[20 imgs],..., 1623 classes in total]\n",
    "# print('data shape:{}'.format(img_list.shape)) # (659, 20, 1, 28, 28)\n",
    "\n",
    "# np.save(os.path.join(root_dir, 'omniglot_test.npy'), img_list)\n",
    "# print('end.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T08:02:03.283025Z",
     "start_time": "2020-04-07T08:02:03.276106Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:34:05.401785Z",
     "start_time": "2020-04-16T02:34:03.474067Z"
    }
   },
   "outputs": [],
   "source": [
    "img_list_train = np.load(os.path.join(root_dir, 'omniglot_train.npy')) # (964, 20, 1, 28, 28)\n",
    "img_list_test = np.load(os.path.join(root_dir, 'omniglot_test.npy')) # (659, 20, 1, 28, 28)\n",
    "\n",
    "x_train = img_list_train\n",
    "x_test = img_list_test\n",
    "# num_classes = img_list.shape[0]\n",
    "datasets = {'train': x_train, 'test': x_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:34:22.871343Z",
     "start_time": "2020-04-16T02:34:21.674782Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB: train (964, 20, 1, 28, 28) test (659, 20, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "### 准备数据迭代器\n",
    "n_way = 20\n",
    "k_spt = 5  ## support data 的个数\n",
    "k_query = 15 ## query data 的个数\n",
    "imgsz = 28\n",
    "resize = imgsz\n",
    "task_num = 16\n",
    "batch_size = task_num\n",
    "\n",
    "indexes = {\"train\": 0, \"test\": 0}\n",
    "datasets = {\"train\": x_train, \"test\": x_test}\n",
    "print(\"DB: train\", x_train.shape, \"test\", x_test.shape)\n",
    "\n",
    "\n",
    "def load_data_cache(dataset):\n",
    "    \"\"\"\n",
    "    Collects several batches data for N-shot learning\n",
    "    :param dataset: [cls_num, 20, 84, 84, 1]\n",
    "    :return: A list with [support_set_x, support_set_y, target_x, target_y] ready to be fed to our networks\n",
    "    \"\"\"\n",
    "    #  take 5 way 1 shot as example: 5 * 1\n",
    "    setsz = k_spt * n_way\n",
    "    querysz = k_query * n_way\n",
    "    data_cache = []\n",
    "\n",
    "    # print('preload next 10 caches of batch_size of batch.')\n",
    "    for sample in range(10):  # num of epochs\n",
    "\n",
    "        x_spts, y_spts, x_qrys, y_qrys = [], [], [], []\n",
    "        for i in range(batch_size):  # one batch means one set\n",
    "\n",
    "            x_spt, y_spt, x_qry, y_qry = [], [], [], []\n",
    "            selected_cls = np.random.choice(dataset.shape[0], n_way, replace =  False) \n",
    "\n",
    "            for j, cur_class in enumerate(selected_cls):\n",
    "\n",
    "                selected_img = np.random.choice(20, k_spt + k_query, replace = False)\n",
    "\n",
    "                # 构造support集和query集\n",
    "                x_spt.append(dataset[cur_class][selected_img[:k_spt]])\n",
    "                x_qry.append(dataset[cur_class][selected_img[k_spt:]])\n",
    "                y_spt.append([j for _ in range(k_spt)])\n",
    "                y_qry.append([j for _ in range(k_query)])\n",
    "\n",
    "            # shuffle inside a batch\n",
    "            perm = np.random.permutation(n_way * k_spt)\n",
    "            x_spt = np.array(x_spt).reshape(n_way * k_spt, 1, resize, resize)[perm]\n",
    "            y_spt = np.array(y_spt).reshape(n_way * k_spt)[perm]\n",
    "            perm = np.random.permutation(n_way * k_query)\n",
    "            x_qry = np.array(x_qry).reshape(n_way * k_query, 1, resize, resize)[perm]\n",
    "            y_qry = np.array(y_qry).reshape(n_way * k_query)[perm]\n",
    " \n",
    "            # append [sptsz, 1, 84, 84] => [batch_size, setsz, 1, 84, 84]\n",
    "            x_spts.append(x_spt)\n",
    "            y_spts.append(y_spt)\n",
    "            x_qrys.append(x_qry)\n",
    "            y_qrys.append(y_qry)\n",
    "\n",
    "#         print(x_spts[0].shape)\n",
    "        # [b, setsz = n_way * k_spt, 1, 84, 84]\n",
    "        x_spts = np.array(x_spts).astype(np.float32).reshape(batch_size, setsz, 1, resize, resize)\n",
    "        y_spts = np.array(y_spts).astype(np.int).reshape(batch_size, setsz)\n",
    "        # [b, qrysz = n_way * k_query, 1, 84, 84]\n",
    "        x_qrys = np.array(x_qrys).astype(np.float32).reshape(batch_size, querysz, 1, resize, resize)\n",
    "        y_qrys = np.array(y_qrys).astype(np.int).reshape(batch_size, querysz)\n",
    "#         print(x_qrys.shape)\n",
    "        data_cache.append([x_spts, y_spts, x_qrys, y_qrys])\n",
    "\n",
    "    return data_cache\n",
    "\n",
    "datasets_cache = {\"train\": load_data_cache(x_train),  # current epoch data cached\n",
    "                       \"test\": load_data_cache(x_test)}\n",
    "\n",
    "def next(mode='train'):\n",
    "    \"\"\"\n",
    "    Gets next batch from the dataset with name.\n",
    "    :param mode: The name of the splitting (one of \"train\", \"val\", \"test\")\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # update cache if indexes is larger than len(data_cache)\n",
    "    if indexes[mode] >= len(datasets_cache[mode]):\n",
    "        indexes[mode] = 0\n",
    "        datasets_cache[mode] = load_data_cache(datasets[mode])\n",
    "\n",
    "    next_batch = datasets_cache[mode][indexes[mode]]\n",
    "    indexes[mode] += 1\n",
    "\n",
    "    return next_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:34:25.602642Z",
     "start_time": "2020-04-16T02:34:25.547982Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from copy import deepcopy,copy\n",
    "        \n",
    "\n",
    "class BaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNet, self).__init__()\n",
    "        self.vars = nn.ParameterList()  ## 包含了所有需要被优化的tensor\n",
    "        self.vars_bn = nn.ParameterList()\n",
    "        \n",
    "        # 第1个conv2d\n",
    "        weight = nn.Parameter(torch.ones(64, 1, 3, 3))\n",
    "        nn.init.kaiming_normal_(weight)\n",
    "        bias = nn.Parameter(torch.zeros(64))\n",
    "        self.vars.extend([weight,bias])\n",
    "        \n",
    "        # 第1个BatchNorm层\n",
    "        weight = nn.Parameter(torch.ones(64))\n",
    "        bias = nn.Parameter(torch.zeros(64))\n",
    "        self.vars.extend([weight,bias])\n",
    "        \n",
    "        running_mean = nn.Parameter(torch.zeros(64), requires_grad= False)\n",
    "        running_var = nn.Parameter(torch.zeros(64), requires_grad= False)\n",
    "        self.vars_bn.extend([running_mean, running_var])\n",
    "        \n",
    "        # 第2个conv2d\n",
    "        weight = nn.Parameter(torch.ones(64, 64, 3, 3))\n",
    "        nn.init.kaiming_normal_(weight)\n",
    "        bias = nn.Parameter(torch.zeros(64))\n",
    "        self.vars.extend([weight,bias])\n",
    "        \n",
    "        # 第2个BatchNorm层\n",
    "        weight = nn.Parameter(torch.ones(64))\n",
    "        bias = nn.Parameter(torch.zeros(64))\n",
    "        self.vars.extend([weight,bias])\n",
    "        \n",
    "        running_mean = nn.Parameter(torch.zeros(64), requires_grad= False)\n",
    "        running_var = nn.Parameter(torch.zeros(64), requires_grad= False)\n",
    "        self.vars_bn.extend([running_mean, running_var])\n",
    "        \n",
    "        # 第3个conv2d\n",
    "        weight = nn.Parameter(torch.ones(64, 64, 3, 3))\n",
    "        nn.init.kaiming_normal_(weight)\n",
    "        bias = nn.Parameter(torch.zeros(64))\n",
    "        self.vars.extend([weight,bias])\n",
    "        \n",
    "        # 第3个BatchNorm层\n",
    "        weight = nn.Parameter(torch.ones(64))\n",
    "        bias = nn.Parameter(torch.zeros(64))\n",
    "        self.vars.extend([weight,bias])\n",
    "        \n",
    "        running_mean = nn.Parameter(torch.zeros(64), requires_grad= False)\n",
    "        running_var = nn.Parameter(torch.zeros(64), requires_grad= False)\n",
    "        self.vars_bn.extend([running_mean, running_var])\n",
    "        \n",
    "        # 第4个conv2d\n",
    "        weight = nn.Parameter(torch.ones(64, 64, 3, 3))\n",
    "        nn.init.kaiming_normal_(weight)\n",
    "        bias = nn.Parameter(torch.zeros(64))\n",
    "        self.vars.extend([weight,bias])\n",
    "        \n",
    "        # 第4个BatchNorm层\n",
    "        weight = nn.Parameter(torch.ones(64))\n",
    "        bias = nn.Parameter(torch.zeros(64))\n",
    "        self.vars.extend([weight,bias])\n",
    "        \n",
    "        running_mean = nn.Parameter(torch.zeros(64), requires_grad= False)\n",
    "        running_var = nn.Parameter(torch.zeros(64), requires_grad= False)\n",
    "        self.vars_bn.extend([running_mean, running_var])\n",
    "        \n",
    "        ##linear\n",
    "        weight = nn.Parameter(torch.ones([20,64]))\n",
    "        bias = nn.Parameter(torch.zeros(20))\n",
    "        self.vars.extend([weight,bias])\n",
    "        \n",
    "    def forward(self, x, params = None, bn_training=True):\n",
    "        '''\n",
    "        :bn_training: set False to not update\n",
    "        :return: \n",
    "        '''\n",
    "        if params is None:\n",
    "            params = self.vars\n",
    "        \n",
    "        weight, bias = params[0], params[1]  # 第1个CONV层\n",
    "        x = F.conv2d(x, weight, bias, stride = 1, padding = 1)\n",
    "        weight, bias = params[2], params[3]  # 第1个BN层\n",
    "        running_mean, running_var = self.vars_bn[0], self.vars_bn[1]\n",
    "        x = F.batch_norm(x, running_mean, running_var, weight=weight,bias =bias, training= bn_training, momentum = 1)\n",
    "        x = F.relu(x, inplace = [True])  #第1个relu\n",
    "        x = F.max_pool2d(x,kernel_size=2)  #第1个MAX_POOL层  \n",
    "        \n",
    "        \n",
    "        \n",
    "        weight, bias = params[4], params[5]  # 第2个CONV层\n",
    "        x = F.conv2d(x, weight, bias, stride = 1, padding = 1)\n",
    "        weight, bias = params[6], params[7]  # 第2个BN层\n",
    "        running_mean, running_var = self.vars_bn[2], self.vars_bn[3]\n",
    "        x = F.batch_norm(x, running_mean, running_var, weight=weight,bias =bias, training= bn_training, momentum=1)\n",
    "        x = F.relu(x, inplace = [True])  #第2个relu\n",
    "        x = F.max_pool2d(x,kernel_size=2)  #第2个MAX_POOL层   \n",
    "        \n",
    "        \n",
    "        weight, bias = params[8], params[9]  # 第3个CONV层\n",
    "        x = F.conv2d(x, weight, bias, stride = 1, padding = 1)\n",
    "        weight, bias = params[10], params[11]  # 第3个BN层\n",
    "        running_mean, running_var = self.vars_bn[4], self.vars_bn[5]\n",
    "        x = F.batch_norm(x, running_mean, running_var, weight=weight,bias =bias, training= bn_training,momentum=1)\n",
    "        x = F.relu(x, inplace = [True])  #第3个relu,\n",
    "        x = F.max_pool2d(x,kernel_size=2)  #第3个MAX_POOL层\n",
    "        \n",
    "        \n",
    "        weight, bias = params[12], params[13]  # 第4个CONV层\n",
    "        x = F.conv2d(x, weight, bias, stride = 1, padding = 1)\n",
    "        weight, bias = params[14], params[15]  # 第4个BN层\n",
    "        running_mean, running_var = self.vars_bn[6], self.vars_bn[7]\n",
    "        x = F.batch_norm(x, running_mean, running_var, weight=weight,bias =bias, training= bn_training)\n",
    "        x = F.max_pool2d(x,kernel_size=2)  #第4个MAX_POOL层\n",
    "        \n",
    "        x = F.relu(x, inplace = [True])  #第4个relu\n",
    "        \n",
    "        x = x.view(x.size(0), -1) ## flatten\n",
    "        weight, bias = params[-2], params[-1]  # linear\n",
    "        x = F.linear(x, weight, bias)\n",
    "        \n",
    "        output = x\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def parameters(self):\n",
    "        \n",
    "        return self.vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T12:00:30.197710Z",
     "start_time": "2020-02-29T12:00:30.186076Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T05:41:40.773998Z",
     "start_time": "2020-02-29T05:41:40.762077Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T03:02:31.026926Z",
     "start_time": "2020-04-17T03:02:30.989680Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaLearner, self).__init__()\n",
    "        self.update_step = 5 ## task-level inner update steps\n",
    "        self.update_step_test = 5\n",
    "        self.net = BaseNet()\n",
    "        self.meta_lr = 0.0008\n",
    "        self.base_lr = 0.075\n",
    "        self.meta_optim = torch.optim.Adam(self.net.parameters(), lr = self.meta_lr)\n",
    "#         self.meta_optim = torch.optim.SGD(self.net.parameters(), lr = self.meta_lr, momentum = 0.9, weight_decay=0.0005)\n",
    "        \n",
    "    def forward(self,x_spt, y_spt, x_qry, y_qry):\n",
    "        # 初始化\n",
    "        task_num, ways, shots, h, w = x_spt.size()\n",
    "        query_size = x_qry.size(1) # 75 = 15 * 5\n",
    "        loss_list_qry = [0 for _ in range(self.update_step + 1)]\n",
    "        correct_list = [0 for _ in range(self.update_step + 1)]\n",
    "        \n",
    "        for i in range(task_num):\n",
    "            ## 第0步更新\n",
    "            y_hat = self.net(x_spt[i], params = None, bn_training=True) # (ways * shots, ways)\n",
    "            loss = F.cross_entropy(y_hat, y_spt[i]) \n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            tuples = zip(grad, self.net.parameters()) ## 将梯度和参数\\theta一一对应起来\n",
    "            # fast_weights这一步相当于求了一个\\theta - \\alpha*\\nabla(L)\n",
    "            fast_weights = list(map(lambda p: p[1] - self.base_lr * p[0], tuples))\n",
    "            # 在query集上测试，计算准确率\n",
    "            # 这一步使用更新前的数据\n",
    "            with torch.no_grad():\n",
    "                y_hat = self.net(x_qry[i], self.net.parameters(), bn_training = True)\n",
    "                loss_qry = F.cross_entropy(y_hat, y_qry[i])\n",
    "                loss_list_qry[0] += loss_qry\n",
    "                pred_qry = F.softmax(y_hat, dim=1).argmax(dim=1)  # size = (75)\n",
    "                correct = torch.eq(pred_qry, y_qry[i]).sum().item()\n",
    "                correct_list[0] += correct\n",
    "            \n",
    "            # 使用更新后的数据在query集上测试。\n",
    "            with torch.no_grad():\n",
    "                y_hat = self.net(x_qry[i], fast_weights, bn_training = True)\n",
    "                loss_qry = F.cross_entropy(y_hat, y_qry[i])\n",
    "                loss_list_qry[1] += loss_qry\n",
    "                pred_qry = F.softmax(y_hat, dim=1).argmax(dim=1)  # size = (75)\n",
    "                correct = torch.eq(pred_qry, y_qry[i]).sum().item()\n",
    "                correct_list[1] += correct   \n",
    "            \n",
    "            for k in range(1, self.update_step):\n",
    "                \n",
    "                y_hat = self.net(x_spt[i], params = fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(y_hat, y_spt[i])\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                tuples = zip(grad, fast_weights) \n",
    "                fast_weights = list(map(lambda p: p[1] - self.base_lr * p[0], tuples))\n",
    "                \n",
    "                if k < self.update_step - 1:\n",
    "                    with torch.no_grad():\n",
    "                        y_hat = self.net(x_qry[i], params = fast_weights, bn_training = True)\n",
    "                        loss_qry = F.cross_entropy(y_hat, y_qry[i])\n",
    "                        loss_list_qry[k+1] += loss_qry\n",
    "                else:\n",
    "                    y_hat = self.net(x_qry[i], params = fast_weights, bn_training = True)\n",
    "                    loss_qry = F.cross_entropy(y_hat, y_qry[i])\n",
    "                    loss_list_qry[k+1] += loss_qry\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    pred_qry = F.softmax(y_hat,dim=1).argmax(dim=1)\n",
    "                    correct = torch.eq(pred_qry, y_qry[i]).sum().item()\n",
    "                    correct_list[k+1] += correct\n",
    "#         print('hello')\n",
    "                \n",
    "        loss_qry = loss_list_qry[-1] / task_num\n",
    "        self.meta_optim.zero_grad() # 梯度清零\n",
    "        loss_qry.backward()\n",
    "        self.meta_optim.step()\n",
    "        \n",
    "        accs = np.array(correct_list) / (query_size * task_num)\n",
    "        loss = np.array(loss_list_qry) / ( task_num)\n",
    "        return accs,loss\n",
    "\n",
    "    \n",
    "    \n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        assert len(x_spt.shape) == 4\n",
    "        \n",
    "        query_size = x_qry.size(0)\n",
    "        correct_list = [0 for _ in range(self.update_step_test + 1)]\n",
    "        \n",
    "        new_net = deepcopy(self.net)\n",
    "        y_hat = new_net(x_spt)\n",
    "        loss = F.cross_entropy(y_hat, y_spt)\n",
    "        grad = torch.autograd.grad(loss, new_net.parameters())\n",
    "        fast_weights = list(map(lambda p:p[1] - self.base_lr * p[0], zip(grad, new_net.parameters())))\n",
    "        \n",
    "        # 在query集上测试，计算准确率\n",
    "        # 这一步使用更新前的数据\n",
    "        with torch.no_grad():\n",
    "            y_hat = new_net(x_qry,  params = new_net.parameters(), bn_training = True)\n",
    "            pred_qry = F.softmax(y_hat, dim=1).argmax(dim=1)  # size = (75)\n",
    "            correct = torch.eq(pred_qry, y_qry).sum().item()\n",
    "            correct_list[0] += correct\n",
    "\n",
    "        # 使用更新后的数据在query集上测试。\n",
    "        with torch.no_grad():\n",
    "            y_hat = new_net(x_qry, params = fast_weights, bn_training = True)\n",
    "            pred_qry = F.softmax(y_hat, dim=1).argmax(dim=1)  # size = (75)\n",
    "            correct = torch.eq(pred_qry, y_qry).sum().item()\n",
    "            correct_list[1] += correct\n",
    "\n",
    "        for k in range(1, self.update_step_test):\n",
    "            y_hat = new_net(x_spt, params = fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(y_hat, y_spt)\n",
    "            grad = torch.autograd.grad(loss, fast_weights)\n",
    "            fast_weights = list(map(lambda p:p[1] - self.base_lr * p[0], zip(grad, fast_weights)))\n",
    "            \n",
    "            y_hat = new_net(x_qry, fast_weights, bn_training=True)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_qry = F.softmax(y_hat, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_qry, y_qry).sum().item()\n",
    "                correct_list[k+1] += correct\n",
    "                \n",
    "        del new_net\n",
    "        accs = np.array(correct_list) / query_size\n",
    "        return accs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T03:02:38.654198Z",
     "start_time": "2020-04-17T03:02:38.651549Z"
    }
   },
   "outputs": [],
   "source": [
    "# net = torch.load('./trained_models/MTL-5000epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T12:33:25.158244Z",
     "start_time": "2020-04-17T03:03:26.192147Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "[0.05       0.155625   0.1775     0.19875    0.22145833 0.25270833]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05008 0.1423  0.1737  0.2052  0.236   0.2651 ]\n",
      "epoch: 100\n",
      "[0.045625   0.50666667 0.65104167 0.74479167 0.79166667 0.819375  ]\n",
      "epoch: 200\n",
      "[0.05104167 0.70208333 0.84291667 0.90270833 0.92166667 0.931875  ]\n",
      "epoch: 300\n",
      "[0.05       0.28020833 0.728125   0.81791667 0.85729167 0.876875  ]\n",
      "epoch: 400\n",
      "[0.05       0.56208333 0.80291667 0.89854167 0.94770833 0.960625  ]\n",
      "epoch: 500\n",
      "[0.05       0.53666667 0.81395833 0.926875   0.948125   0.95958333]\n",
      "epoch: 600\n",
      "[0.05       0.54020833 0.85041667 0.95395833 0.9625     0.966875  ]\n",
      "epoch: 700\n",
      "[0.05       0.4775     0.84375    0.9425     0.94833333 0.94729167]\n",
      "epoch: 800\n",
      "[0.05       0.47833333 0.82541667 0.90229167 0.908125   0.9175    ]\n",
      "epoch: 900\n",
      "[0.05       0.46354167 0.84291667 0.91666667 0.91041667 0.92979167]\n",
      "epoch: 1000\n",
      "[0.05       0.44541667 0.80625    0.87041667 0.87979167 0.90583333]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.3694 0.729  0.783  0.8086 0.857 ]\n",
      "epoch: 1100\n",
      "[0.05       0.441875   0.80333333 0.85416667 0.89520833 0.92708333]\n",
      "epoch: 1200\n",
      "[0.05       0.143125   0.72583333 0.78479167 0.84958333 0.900625  ]\n",
      "epoch: 1300\n",
      "[0.05       0.05       0.05       0.68291667 0.82416667 0.8975    ]\n",
      "epoch: 1400\n",
      "[0.05     0.05     0.05     0.773125 0.896875 0.9275  ]\n",
      "epoch: 1500\n",
      "[0.05       0.05       0.05       0.82208333 0.91541667 0.93770833]\n",
      "epoch: 1600\n",
      "[0.05       0.05       0.05       0.84416667 0.91583333 0.93916667]\n",
      "epoch: 1700\n",
      "[0.05       0.05       0.05       0.840625   0.91958333 0.94125   ]\n",
      "epoch: 1800\n",
      "[0.05       0.05       0.05       0.8875     0.93375    0.94729167]\n",
      "epoch: 1900\n",
      "[0.05       0.05       0.05       0.87916667 0.944375   0.954375  ]\n",
      "epoch: 2000\n",
      "[0.05       0.05       0.05       0.90416667 0.92833333 0.94395833]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.8057 0.8794 0.906 ]\n",
      "epoch: 2100\n",
      "[0.05       0.05       0.05       0.91       0.94291667 0.95458333]\n",
      "epoch: 2200\n",
      "[0.05       0.05       0.05       0.90625    0.95458333 0.964375  ]\n",
      "epoch: 2300\n",
      "[0.05       0.05       0.05       0.91291667 0.94145833 0.94395833]\n",
      "epoch: 2400\n",
      "[0.05       0.05       0.05       0.935625   0.95541667 0.96125   ]\n",
      "epoch: 2500\n",
      "[0.05       0.05       0.05       0.94041667 0.96916667 0.97625   ]\n",
      "epoch: 2600\n",
      "[0.05       0.05       0.05       0.94104167 0.96875    0.97270833]\n",
      "epoch: 2700\n",
      "[0.05       0.05       0.05       0.95479167 0.96895833 0.97395833]\n",
      "epoch: 2800\n",
      "[0.05       0.05       0.05       0.955      0.97791667 0.97770833]\n",
      "epoch: 2900\n",
      "[0.05       0.05       0.05       0.95583333 0.97125    0.978125  ]\n",
      "epoch: 3000\n",
      "[0.05     0.05     0.05     0.946875 0.969375 0.975   ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.8594 0.9204 0.933 ]\n",
      "epoch: 3100\n",
      "[0.05       0.05       0.05       0.95583333 0.97541667 0.97229167]\n",
      "epoch: 3200\n",
      "[0.05       0.05       0.05       0.955      0.976875   0.97770833]\n",
      "epoch: 3300\n",
      "[0.05       0.05       0.05       0.96083333 0.98229167 0.98208333]\n",
      "epoch: 3400\n",
      "[0.05       0.05       0.05       0.94354167 0.97020833 0.97583333]\n",
      "epoch: 3500\n",
      "[0.05       0.05       0.05       0.96895833 0.97583333 0.97479167]\n",
      "epoch: 3600\n",
      "[0.05       0.05       0.05       0.95833333 0.97104167 0.97645833]\n",
      "epoch: 3700\n",
      "[0.05       0.05       0.05       0.95708333 0.97604167 0.97895833]\n",
      "epoch: 3800\n",
      "[0.05       0.05       0.05       0.96770833 0.97895833 0.98083333]\n",
      "epoch: 3900\n",
      "[0.05       0.05       0.05       0.96       0.97666667 0.97979167]\n",
      "epoch: 4000\n",
      "[0.05       0.05       0.05       0.97333333 0.97875    0.976875  ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.8857 0.933  0.943 ]\n",
      "epoch: 4100\n",
      "[0.05       0.05       0.05       0.96625    0.9775     0.98041667]\n",
      "epoch: 4200\n",
      "[0.05       0.05       0.05       0.97125    0.9825     0.98354167]\n",
      "epoch: 4300\n",
      "[0.05       0.05       0.05       0.96604167 0.976875   0.97625   ]\n",
      "epoch: 4400\n",
      "[0.05       0.05       0.05       0.97520833 0.983125   0.98583333]\n",
      "epoch: 4500\n",
      "[0.05       0.05       0.05       0.9675     0.97333333 0.98083333]\n",
      "epoch: 4600\n",
      "[0.05       0.05       0.05       0.96291667 0.96958333 0.97291667]\n",
      "epoch: 4700\n",
      "[0.05       0.05       0.05       0.96958333 0.98229167 0.98458333]\n",
      "epoch: 4800\n",
      "[0.05       0.05       0.05       0.97       0.98395833 0.98416667]\n",
      "epoch: 4900\n",
      "[0.05       0.05       0.05       0.97333333 0.985      0.98479167]\n",
      "epoch: 5000\n",
      "[0.05       0.05       0.05       0.97854167 0.98604167 0.988125  ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.8945 0.9355 0.943 ]\n",
      "epoch: 5100\n",
      "[0.05       0.05       0.05       0.97125    0.976875   0.98041667]\n",
      "epoch: 5200\n",
      "[0.05       0.05       0.05       0.97375    0.98020833 0.98208333]\n",
      "epoch: 5300\n",
      "[0.05       0.05       0.05       0.97583333 0.98520833 0.98895833]\n",
      "epoch: 5400\n",
      "[0.05       0.05       0.05       0.95729167 0.97083333 0.97479167]\n",
      "epoch: 5500\n",
      "[0.05       0.05       0.05       0.97270833 0.97729167 0.983125  ]\n",
      "epoch: 5600\n",
      "[0.05       0.05       0.05       0.97854167 0.99       0.99104167]\n",
      "epoch: 5700\n",
      "[0.05       0.05       0.05       0.97270833 0.98395833 0.98291667]\n",
      "epoch: 5800\n",
      "[0.05       0.05       0.05       0.9825     0.98791667 0.98875   ]\n",
      "epoch: 5900\n",
      "[0.05       0.05       0.05       0.974375   0.98291667 0.98541667]\n",
      "epoch: 6000\n",
      "[0.05       0.05       0.05       0.97479167 0.98416667 0.98291667]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.887  0.9316 0.9395]\n",
      "epoch: 6100\n",
      "[0.05       0.05       0.05       0.98       0.988125   0.98833333]\n",
      "epoch: 6200\n",
      "[0.05       0.05       0.05       0.973125   0.98125    0.98166667]\n",
      "epoch: 6300\n",
      "[0.05       0.05       0.05       0.97395833 0.979375   0.98458333]\n",
      "epoch: 6400\n",
      "[0.05       0.05       0.05       0.97791667 0.98541667 0.98791667]\n",
      "epoch: 6500\n",
      "[0.05       0.05       0.05       0.97791667 0.978125   0.98083333]\n",
      "epoch: 6600\n",
      "[0.05       0.05       0.05       0.98041667 0.98520833 0.98583333]\n",
      "epoch: 6700\n",
      "[0.05       0.05       0.05       0.98645833 0.98979167 0.99166667]\n",
      "epoch: 6800\n",
      "[0.05       0.05       0.05       0.97854167 0.98270833 0.98666667]\n",
      "epoch: 6900\n",
      "[0.05       0.05       0.05       0.96666667 0.97354167 0.97708333]\n",
      "epoch: 7000\n",
      "[0.05       0.05       0.05       0.98354167 0.98458333 0.98458333]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9087 0.939  0.944 ]\n",
      "epoch: 7100\n",
      "[0.05       0.05       0.05       0.98       0.985      0.98583333]\n",
      "epoch: 7200\n",
      "[0.05       0.05       0.05       0.97291667 0.98541667 0.98666667]\n",
      "epoch: 7300\n",
      "[0.05       0.05       0.05       0.97625    0.98229167 0.98208333]\n",
      "epoch: 7400\n",
      "[0.05       0.05       0.05       0.98145833 0.98916667 0.98875   ]\n",
      "epoch: 7500\n",
      "[0.05       0.05       0.05       0.98041667 0.983125   0.98333333]\n",
      "epoch: 7600\n",
      "[0.05       0.05       0.05       0.97416667 0.97854167 0.98458333]\n",
      "epoch: 7700\n",
      "[0.05       0.05       0.05       0.979375   0.98520833 0.985625  ]\n",
      "epoch: 7800\n",
      "[0.05       0.05       0.05       0.975625   0.98270833 0.98145833]\n",
      "epoch: 7900\n",
      "[0.05       0.05       0.05       0.98520833 0.98729167 0.98875   ]\n",
      "epoch: 8000\n",
      "[0.05       0.05       0.05       0.98104167 0.98666667 0.98625   ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9126 0.9395 0.9434]\n",
      "epoch: 8100\n",
      "[0.05       0.05       0.05       0.98       0.98625    0.98729167]\n",
      "epoch: 8200\n",
      "[0.05       0.05       0.05       0.98375    0.98916667 0.98958333]\n",
      "epoch: 8300\n",
      "[0.05       0.05       0.05       0.98166667 0.98666667 0.986875  ]\n",
      "epoch: 8400\n",
      "[0.05       0.05       0.05       0.97020833 0.97604167 0.98041667]\n",
      "epoch: 8500\n",
      "[0.05       0.05       0.05       0.98375    0.98875    0.99020833]\n",
      "epoch: 8600\n",
      "[0.05       0.05       0.05       0.98166667 0.98208333 0.98583333]\n",
      "epoch: 8700\n",
      "[0.05       0.05       0.05       0.98458333 0.985625   0.9875    ]\n",
      "epoch: 8800\n",
      "[0.05       0.05       0.05       0.98229167 0.98708333 0.98645833]\n",
      "epoch: 8900\n",
      "[0.05       0.05       0.05       0.985625   0.99125    0.99270833]\n",
      "epoch: 9000\n",
      "[0.05       0.05       0.05       0.980625   0.98625    0.98854167]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9062 0.9355 0.94  ]\n",
      "epoch: 9100\n",
      "[0.05       0.05       0.05       0.98708333 0.99229167 0.99083333]\n",
      "epoch: 9200\n",
      "[0.05       0.05       0.05       0.985625   0.986875   0.98979167]\n",
      "epoch: 9300\n",
      "[0.05       0.05       0.05       0.986875   0.98479167 0.98583333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9400\n",
      "[0.05       0.05       0.05       0.98520833 0.99145833 0.99270833]\n",
      "epoch: 9500\n",
      "[0.05       0.05       0.05       0.981875   0.98833333 0.989375  ]\n",
      "epoch: 9600\n",
      "[0.05       0.05       0.05       0.980625   0.99020833 0.99208333]\n",
      "epoch: 9700\n",
      "[0.05       0.05       0.05       0.98375    0.98708333 0.98875   ]\n",
      "epoch: 9800\n",
      "[0.05       0.05       0.05       0.985      0.99125    0.99104167]\n",
      "epoch: 9900\n",
      "[0.05       0.05       0.05       0.98270833 0.983125   0.98375   ]\n",
      "epoch: 10000\n",
      "[0.05       0.05       0.05       0.97583333 0.98104167 0.98270833]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9106 0.9365 0.941 ]\n",
      "epoch: 10100\n",
      "[0.05       0.05       0.05       0.97854167 0.9825     0.98125   ]\n",
      "epoch: 10200\n",
      "[0.05       0.05       0.05       0.97770833 0.98104167 0.98020833]\n",
      "epoch: 10300\n",
      "[0.05       0.05       0.05       0.981875   0.98458333 0.98604167]\n",
      "epoch: 10400\n",
      "[0.05       0.05       0.05       0.98020833 0.98479167 0.98625   ]\n",
      "epoch: 10500\n",
      "[0.05       0.05       0.05       0.98229167 0.98854167 0.99083333]\n",
      "epoch: 10600\n",
      "[0.05       0.05       0.05       0.99041667 0.99041667 0.99208333]\n",
      "epoch: 10700\n",
      "[0.05       0.05       0.05       0.97770833 0.98541667 0.98791667]\n",
      "epoch: 10800\n",
      "[0.05       0.05       0.05       0.98875    0.99354167 0.99416667]\n",
      "epoch: 10900\n",
      "[0.05       0.05       0.05       0.99208333 0.99375    0.99416667]\n",
      "epoch: 11000\n",
      "[0.05       0.05       0.05       0.98145833 0.98645833 0.98416667]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.914  0.9365 0.9404]\n",
      "epoch: 11100\n",
      "[0.05       0.05       0.05       0.98375    0.99041667 0.99125   ]\n",
      "epoch: 11200\n",
      "[0.05       0.05       0.05       0.97979167 0.98875    0.99020833]\n",
      "epoch: 11300\n",
      "[0.05       0.05       0.05       0.989375   0.98895833 0.99041667]\n",
      "epoch: 11400\n",
      "[0.05       0.05       0.05       0.99125    0.99291667 0.993125  ]\n",
      "epoch: 11500\n",
      "[0.05       0.05       0.05       0.99020833 0.99083333 0.990625  ]\n",
      "epoch: 11600\n",
      "[0.05       0.05       0.05       0.98020833 0.98395833 0.985625  ]\n",
      "epoch: 11700\n",
      "[0.05       0.05       0.05       0.98916667 0.99104167 0.99083333]\n",
      "epoch: 11800\n",
      "[0.05       0.05       0.05       0.98291667 0.99083333 0.99166667]\n",
      "epoch: 11900\n",
      "[0.05       0.05       0.05       0.98854167 0.99208333 0.99229167]\n",
      "epoch: 12000\n",
      "[0.05       0.05       0.05       0.98291667 0.98708333 0.98958333]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9106 0.9326 0.9365]\n",
      "epoch: 12100\n",
      "[0.05       0.05       0.05       0.989375   0.99104167 0.99208333]\n",
      "epoch: 12200\n",
      "[0.05       0.05       0.05       0.98958333 0.990625   0.99083333]\n",
      "epoch: 12300\n",
      "[0.05       0.05       0.05       0.98791667 0.991875   0.99208333]\n",
      "epoch: 12400\n",
      "[0.05       0.05       0.05       0.99145833 0.99625    0.99625   ]\n",
      "epoch: 12500\n",
      "[0.05       0.05       0.05       0.98395833 0.98604167 0.98729167]\n",
      "epoch: 12600\n",
      "[0.05       0.05       0.05       0.99229167 0.99354167 0.991875  ]\n",
      "epoch: 12700\n",
      "[0.05       0.05       0.05       0.99083333 0.99520833 0.99541667]\n",
      "epoch: 12800\n",
      "[0.05       0.05       0.05       0.99104167 0.99291667 0.9925    ]\n",
      "epoch: 12900\n",
      "[0.05       0.05       0.05       0.98979167 0.994375   0.99520833]\n",
      "epoch: 13000\n",
      "[0.05       0.05       0.05       0.98875    0.9925     0.99583333]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.912  0.932  0.9355]\n",
      "epoch: 13100\n",
      "[0.05       0.05       0.05       0.98645833 0.988125   0.98958333]\n",
      "epoch: 13200\n",
      "[0.05       0.05       0.05       0.99270833 0.99645833 0.99666667]\n",
      "epoch: 13300\n",
      "[0.05       0.05       0.05       0.98895833 0.99041667 0.99229167]\n",
      "epoch: 13400\n",
      "[0.05       0.05       0.05       0.97958333 0.98291667 0.98354167]\n",
      "epoch: 13500\n",
      "[0.05       0.05       0.05       0.98791667 0.98854167 0.98916667]\n",
      "epoch: 13600\n",
      "[0.05       0.05       0.05       0.9825     0.98583333 0.985625  ]\n",
      "epoch: 13700\n",
      "[0.05       0.05       0.05       0.97895833 0.98479167 0.985625  ]\n",
      "epoch: 13800\n",
      "[0.05       0.05       0.05       0.98833333 0.995625   0.99645833]\n",
      "epoch: 13900\n",
      "[0.05       0.05       0.05       0.98770833 0.99416667 0.995     ]\n",
      "epoch: 14000\n",
      "[0.05       0.05       0.05       0.98791667 0.988125   0.988125  ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9087 0.9297 0.9326]\n",
      "epoch: 14100\n",
      "[0.05       0.05       0.05       0.99083333 0.99229167 0.99270833]\n",
      "epoch: 14200\n",
      "[0.05       0.05       0.05       0.98125    0.99270833 0.993125  ]\n",
      "epoch: 14300\n",
      "[0.05       0.05       0.05       0.98916667 0.99333333 0.99291667]\n",
      "epoch: 14400\n",
      "[0.05       0.05       0.05       0.98333333 0.98479167 0.98854167]\n",
      "epoch: 14500\n",
      "[0.05     0.05     0.05     0.983125 0.99125  0.99125 ]\n",
      "epoch: 14600\n",
      "[0.05       0.05       0.05       0.99083333 0.99229167 0.99229167]\n",
      "epoch: 14700\n",
      "[0.05       0.05       0.05       0.98125    0.98520833 0.99041667]\n",
      "epoch: 14800\n",
      "[0.05       0.05       0.05       0.985      0.98375    0.98333333]\n",
      "epoch: 14900\n",
      "[0.05       0.05       0.05       0.990625   0.99229167 0.994375  ]\n",
      "epoch: 15000\n",
      "[0.05       0.05       0.05       0.98541667 0.98375    0.98395833]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05    0.05002 0.05    0.914   0.931   0.9336 ]\n",
      "epoch: 15100\n",
      "[0.05       0.05       0.05       0.99291667 0.995625   0.99541667]\n",
      "epoch: 15200\n",
      "[0.05       0.05       0.05       0.98083333 0.98479167 0.98375   ]\n",
      "epoch: 15300\n",
      "[0.05       0.05       0.05       0.98479167 0.98541667 0.98625   ]\n",
      "epoch: 15400\n",
      "[0.05       0.05       0.05       0.98729167 0.989375   0.98979167]\n",
      "epoch: 15500\n",
      "[0.05       0.05       0.05       0.99583333 0.99645833 0.99645833]\n",
      "epoch: 15600\n",
      "[0.05       0.05       0.05       0.99083333 0.99291667 0.99375   ]\n",
      "epoch: 15700\n",
      "[0.05       0.05       0.05       0.98291667 0.9875     0.98770833]\n",
      "epoch: 15800\n",
      "[0.05       0.05       0.05       0.99395833 0.99416667 0.99416667]\n",
      "epoch: 15900\n",
      "[0.05       0.05       0.05       0.9875     0.98833333 0.98875   ]\n",
      "epoch: 16000\n",
      "[0.05       0.05       0.05       0.9875     0.99020833 0.990625  ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05    0.05008 0.05    0.9116  0.9297  0.932  ]\n",
      "epoch: 16100\n",
      "[0.05       0.05       0.05       0.993125   0.99541667 0.995625  ]\n",
      "epoch: 16200\n",
      "[0.05       0.05       0.05       0.98270833 0.98791667 0.989375  ]\n",
      "epoch: 16300\n",
      "[0.05       0.05       0.05       0.986875   0.99083333 0.99145833]\n",
      "epoch: 16400\n",
      "[0.05       0.05       0.05       0.9875     0.99020833 0.99041667]\n",
      "epoch: 16500\n",
      "[0.05       0.05       0.05       0.99583333 0.996875   0.9975    ]\n",
      "epoch: 16600\n",
      "[0.05       0.05       0.05       0.98666667 0.98791667 0.988125  ]\n",
      "epoch: 16700\n",
      "[0.05       0.05       0.05       0.98666667 0.98958333 0.98979167]\n",
      "epoch: 16800\n",
      "[0.05       0.05       0.05       0.99291667 0.99458333 0.995     ]\n",
      "epoch: 16900\n",
      "[0.05       0.05       0.05       0.99375    0.99541667 0.99541667]\n",
      "epoch: 17000\n",
      "[0.05       0.05       0.05       0.990625   0.990625   0.99208333]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05    0.05002 0.05    0.9136  0.9316  0.934  ]\n",
      "epoch: 17100\n",
      "[0.05       0.05       0.05       0.99291667 0.99479167 0.99479167]\n",
      "epoch: 17200\n",
      "[0.05     0.05     0.05     0.978125 0.98125  0.984375]\n",
      "epoch: 17300\n",
      "[0.05       0.05       0.05       0.99229167 0.99541667 0.99541667]\n",
      "epoch: 17400\n",
      "[0.05       0.05       0.05       0.99479167 0.99541667 0.99520833]\n",
      "epoch: 17500\n",
      "[0.05       0.05       0.05       0.98604167 0.99125    0.99125   ]\n",
      "epoch: 17600\n",
      "[0.05       0.05       0.05       0.98625    0.99104167 0.99208333]\n",
      "epoch: 17700\n",
      "[0.05       0.05       0.05       0.99375    0.99583333 0.99604167]\n",
      "epoch: 17800\n",
      "[0.05       0.05       0.05       0.98895833 0.99229167 0.9925    ]\n",
      "epoch: 17900\n",
      "[0.05       0.05       0.05       0.9875     0.99208333 0.99291667]\n",
      "epoch: 18000\n",
      "[0.05       0.05       0.05       0.98229167 0.98520833 0.98604167]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.911  0.9272 0.9307]\n",
      "epoch: 18100\n",
      "[0.05       0.05       0.05       0.99291667 0.99270833 0.99208333]\n",
      "epoch: 18200\n",
      "[0.05       0.05       0.05       0.98833333 0.98645833 0.98729167]\n",
      "epoch: 18300\n",
      "[0.05       0.05       0.05       0.98916667 0.99229167 0.9925    ]\n",
      "epoch: 18400\n",
      "[0.05       0.05       0.05       0.99208333 0.99416667 0.994375  ]\n",
      "epoch: 18500\n",
      "[0.05       0.05       0.05       0.99       0.99375    0.99395833]\n",
      "epoch: 18600\n",
      "[0.05       0.05       0.05       0.98916667 0.99083333 0.99104167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18700\n",
      "[0.05       0.05       0.05       0.99145833 0.993125   0.99333333]\n",
      "epoch: 18800\n",
      "[0.05       0.05       0.05       0.99666667 0.99604167 0.99625   ]\n",
      "epoch: 18900\n",
      "[0.05       0.05       0.05       0.9925     0.995      0.99520833]\n",
      "epoch: 19000\n",
      "[0.05       0.05       0.05       0.98354167 0.98666667 0.98708333]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05    0.05002 0.05    0.91    0.927   0.9297 ]\n",
      "epoch: 19100\n",
      "[0.05       0.05       0.05       0.99104167 0.993125   0.99291667]\n",
      "epoch: 19200\n",
      "[0.05       0.05       0.05       0.985625   0.98583333 0.98604167]\n",
      "epoch: 19300\n",
      "[0.05       0.05       0.05       0.99041667 0.99229167 0.9925    ]\n",
      "epoch: 19400\n",
      "[0.05       0.05       0.05       0.988125   0.993125   0.99270833]\n",
      "epoch: 19500\n",
      "[0.05       0.05       0.05       0.98895833 0.990625   0.98979167]\n",
      "epoch: 19600\n",
      "[0.05       0.05       0.05       0.99375    0.994375   0.99395833]\n",
      "epoch: 19700\n",
      "[0.05       0.05       0.05       0.98979167 0.994375   0.99458333]\n",
      "epoch: 19800\n",
      "[0.05       0.05       0.05       0.990625   0.994375   0.99458333]\n",
      "epoch: 19900\n",
      "[0.05       0.05       0.05       0.99125    0.99375    0.99416667]\n",
      "epoch: 20000\n",
      "[0.05       0.05       0.05       0.98645833 0.98625    0.98958333]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9146 0.929  0.931 ]\n",
      "epoch: 20100\n",
      "[0.05       0.05       0.05       0.99541667 0.99625    0.99625   ]\n",
      "epoch: 20200\n",
      "[0.05     0.05     0.05     0.99     0.991875 0.9925  ]\n",
      "epoch: 20300\n",
      "[0.05       0.05       0.05       0.99270833 0.99395833 0.99625   ]\n",
      "epoch: 20400\n",
      "[0.05       0.05       0.05       0.990625   0.99229167 0.9925    ]\n",
      "epoch: 20500\n",
      "[0.05     0.05     0.05     0.99375  0.994375 0.994375]\n",
      "epoch: 20600\n",
      "[0.05       0.05       0.05       0.98895833 0.99270833 0.991875  ]\n",
      "epoch: 20700\n",
      "[0.05       0.05       0.05       0.990625   0.99083333 0.99145833]\n",
      "epoch: 20800\n",
      "[0.05       0.05       0.05       0.991875   0.99270833 0.993125  ]\n",
      "epoch: 20900\n",
      "[0.05       0.05       0.05       0.99041667 0.99458333 0.99479167]\n",
      "epoch: 21000\n",
      "[0.05     0.05     0.05     0.9875   0.991875 0.99125 ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9097 0.9253 0.9277]\n",
      "epoch: 21100\n",
      "[0.05       0.05       0.05       0.99270833 0.99333333 0.99395833]\n",
      "epoch: 21200\n",
      "[0.05       0.05       0.05       0.98541667 0.98541667 0.98583333]\n",
      "epoch: 21300\n",
      "[0.05       0.05       0.05       0.9925     0.99375    0.99395833]\n",
      "epoch: 21400\n",
      "[0.05       0.05       0.05       0.98458333 0.98791667 0.98854167]\n",
      "epoch: 21500\n",
      "[0.05       0.05       0.05       0.99229167 0.995625   0.995625  ]\n",
      "epoch: 21600\n",
      "[0.05       0.05       0.05       0.985      0.98520833 0.986875  ]\n",
      "epoch: 21700\n",
      "[0.05       0.05       0.05       0.99520833 0.99541667 0.99625   ]\n",
      "epoch: 21800\n",
      "[0.05       0.05       0.05       0.989375   0.99416667 0.995     ]\n",
      "epoch: 21900\n",
      "[0.05       0.05       0.05       0.98916667 0.99458333 0.99479167]\n",
      "epoch: 22000\n",
      "[0.05       0.05       0.05       0.98291667 0.98416667 0.9875    ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9146 0.9277 0.9297]\n",
      "epoch: 22100\n",
      "[0.05       0.05       0.05       0.99083333 0.99333333 0.99333333]\n",
      "epoch: 22200\n",
      "[0.05       0.05       0.05       0.99125    0.994375   0.99333333]\n",
      "epoch: 22300\n",
      "[0.05       0.05       0.05       0.98604167 0.99041667 0.98979167]\n",
      "epoch: 22400\n",
      "[0.05       0.05       0.05       0.99520833 0.99604167 0.99604167]\n",
      "epoch: 22500\n",
      "[0.05       0.05       0.05       0.99125    0.99333333 0.99354167]\n",
      "epoch: 22600\n",
      "[0.05       0.05       0.05       0.99479167 0.99583333 0.99583333]\n",
      "epoch: 22700\n",
      "[0.05       0.05       0.05       0.995      0.994375   0.99520833]\n",
      "epoch: 22800\n",
      "[0.05       0.05       0.05       0.98083333 0.98770833 0.98770833]\n",
      "epoch: 22900\n",
      "[0.05       0.05       0.05       0.99       0.990625   0.99020833]\n",
      "epoch: 23000\n",
      "[0.05       0.05       0.05       0.994375   0.99520833 0.995625  ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05   0.05   0.05   0.9067 0.9233 0.926 ]\n",
      "epoch: 23100\n",
      "[0.05       0.05       0.05       0.995      0.99479167 0.99583333]\n",
      "epoch: 23200\n",
      "[0.05       0.05       0.05       0.99020833 0.995      0.99520833]\n",
      "epoch: 23300\n",
      "[0.05       0.05       0.05       0.991875   0.99416667 0.99479167]\n",
      "epoch: 23400\n",
      "[0.05       0.05       0.05       0.99125    0.99104167 0.99145833]\n",
      "epoch: 23500\n",
      "[0.05       0.05       0.05       0.98875    0.99104167 0.99104167]\n",
      "epoch: 23600\n",
      "[0.05       0.05       0.05       0.98916667 0.98729167 0.98583333]\n",
      "epoch: 23700\n",
      "[0.05       0.05       0.05       0.985625   0.9875     0.98854167]\n",
      "epoch: 23800\n",
      "[0.05       0.05       0.05       0.99291667 0.995      0.995     ]\n",
      "epoch: 23900\n",
      "[0.05       0.05       0.05       0.98875    0.991875   0.99166667]\n",
      "epoch: 24000\n",
      "[0.05       0.05       0.05       0.99770833 0.998125   0.998125  ]\n",
      "在mean process之前： (992, 6)\n",
      "测试集准确率: [0.05    0.05002 0.05    0.908   0.923   0.925  ]\n",
      "epoch: 24100\n",
      "[0.05       0.05       0.05       0.99125    0.9925     0.99395833]\n",
      "epoch: 24200\n",
      "[0.05       0.05       0.05       0.990625   0.99145833 0.99083333]\n",
      "epoch: 24300\n",
      "[0.05       0.05       0.05       0.9925     0.99395833 0.99458333]\n",
      "epoch: 24400\n",
      "[0.05       0.05       0.05       0.99416667 0.99375    0.99416667]\n",
      "epoch: 24500\n",
      "[0.05       0.05       0.05       0.99520833 0.99666667 0.996875  ]\n",
      "epoch: 24600\n",
      "[0.05       0.05       0.05       0.98916667 0.98958333 0.991875  ]\n",
      "epoch: 24700\n",
      "[0.05       0.05       0.05       0.99583333 0.99666667 0.99833333]\n",
      "epoch: 24800\n",
      "[0.05       0.05       0.05       0.995      0.99541667 0.99583333]\n",
      "epoch: 24900\n",
      "[0.05       0.05       0.05       0.99333333 0.99541667 0.99583333]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-47c485cdc60c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_qry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_qry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0maccs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_spt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_spt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_qry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_qry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-dddb511e3a08>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_spt, y_spt, x_qry, y_qry)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mfast_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_lr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-dddb511e3a08>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mfast_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_lr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## omniglot\n",
    "import random\n",
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "\n",
    "import time\n",
    "device = torch.device('cuda:3')\n",
    "\n",
    "meta = MetaLearner().to(device)\n",
    "\n",
    "epochs = 60001\n",
    "for step in range(epochs):\n",
    "    start = time.time()\n",
    "    x_spt, y_spt, x_qry, y_qry = next('train')\n",
    "    x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device),\\\n",
    "                                 torch.from_numpy(y_spt).to(device),\\\n",
    "                                 torch.from_numpy(x_qry).to(device),\\\n",
    "                                 torch.from_numpy(y_qry).to(device)\n",
    "    accs,loss = meta(x_spt, y_spt, x_qry, y_qry)\n",
    "    end = time.time()\n",
    "    if step % 100 == 0:\n",
    "        print(\"epoch:\" ,step)\n",
    "        print(accs)\n",
    "#         print(loss)\n",
    "        \n",
    "    if step % 1000 == 0:\n",
    "        accs = []\n",
    "        for _ in range(1000//task_num):\n",
    "            # db_train.next('test')\n",
    "            x_spt, y_spt, x_qry, y_qry = next('test')\n",
    "            x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device),\\\n",
    "                                         torch.from_numpy(y_spt).to(device),\\\n",
    "                                         torch.from_numpy(x_qry).to(device),\\\n",
    "                                         torch.from_numpy(y_qry).to(device)\n",
    "\n",
    "            \n",
    "            for x_spt_one, y_spt_one, x_qry_one, y_qry_one in zip(x_spt, y_spt, x_qry, y_qry):\n",
    "                test_acc = meta.finetunning(x_spt_one, y_spt_one, x_qry_one, y_qry_one)\n",
    "                accs.append(test_acc)\n",
    "        print('在mean process之前：',np.array(accs).shape)\n",
    "        accs = np.array(accs).mean(axis=0).astype(np.float16)\n",
    "        print('测试集准确率:',accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T03:00:56.266331Z",
     "start_time": "2020-03-01T03:00:56.205955Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML3.6",
   "language": "python",
   "name": "ml3.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
